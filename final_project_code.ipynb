{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b58c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "images_path = r\"C:\\Users\\osher\\Desktop\\second_degree\\final_project\\dataset\\images\"\n",
    "MAX_IMAGES = 50  # Limit to 50 images for now\n",
    "\n",
    "# === LOAD IMAGES INTO MEMORY ===\n",
    "image_files = sorted([\n",
    "    file for file in os.listdir(images_path)\n",
    "    if file.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "])[:MAX_IMAGES]\n",
    "\n",
    "images = []\n",
    "for file in image_files:\n",
    "    img_path = os.path.join(images_path, file)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    images.append((file, img))\n",
    "\n",
    "print(f\"✅ Loaded {len(images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DISPLAY IMAGES IN A GRID ===\n",
    "n_cols = 5\n",
    "n_rows = (len(images) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 3))\n",
    "fig.suptitle(\"Preview of First 50 Images\", fontsize=18)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(images):\n",
    "        filename, img = images[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(filename, fontsize=8)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30308a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD MODEL AND PROCESSOR ===\n",
    "print(\"[INFO] Loading Qwen2.5-VL-3B-Instruct model...\")\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "\n",
    "print(\"✅ Model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e17020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INFERENCE CONFIG ===\n",
    "question = \"What should I do to get to the door?\"\n",
    "\n",
    "# === PROCESS EACH IMAGE ===\n",
    "for i, (filename, image) in enumerate(images, 1):\n",
    "    print(f\"\\n[{i:02d}] Processing {filename}...\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": question},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    print(f\"🔍 {filename} → {output_text[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
